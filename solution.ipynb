{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa7ff55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available:  False\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Is CUDA available: \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207a4125",
   "metadata": {},
   "source": [
    "### Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d584d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "\n",
    "train_dataset_path = 'dataset/ogyeiv2/train'\n",
    "dataset = ImageFolder(train_dataset_path)\n",
    "train_dataset, val_dataset = random_split(dataset, [0.8, 0.2]) \n",
    "\n",
    "test_dataset_path = 'dataset/ogyeiv2/test'\n",
    "test_dataset_origin = ImageFolder(test_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cd8a55",
   "metadata": {},
   "source": [
    "We're going to use a model pretrained on ImageNet, so it's best to normalize our dataset accordingly to match the model's training data.\n",
    "\n",
    "The transforms.ColorJitter function simulates lighting and exposure changes by randomly varying image brightness and contrast by Â±25%. This helps the model stay robust to illumination differences and focus on shape and texture instead of light intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1951ccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformDataset(Dataset):\n",
    "  def __init__(self, dataset, transforms):\n",
    "    super(TransformDataset, self).__init__()\n",
    "    self.dataset = dataset\n",
    "    self.transforms = transforms\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.dataset)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    x, y = self.dataset[idx]\n",
    "    return self.transforms(x), y\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ColorJitter(brightness=0.25, contrast=0.25),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "eval_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = TransformDataset(train_dataset, train_transforms)\n",
    "val_dataset = TransformDataset(val_dataset, eval_transforms)\n",
    "test_dataset = TransformDataset(test_dataset_origin, eval_transforms)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28d87b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 84\n",
      "Class names: ['acc_long_600_mg', 'advil_ultra_forte', 'akineton_2_mg', 'algoflex_forte_dolo_400_mg', 'algoflex_rapid_400_mg', 'algopyrin_500_mg', 'ambroxol_egis_30_mg', 'apranax_550_mg', 'aspirin_ultra_500_mg', 'atoris_20_mg', 'atorvastatin_teva_20_mg', 'betaloc_50_mg', 'bila_git', 'c_vitamin_teva_500_mg', 'calci_kid', 'cataflam_50_mg', 'cataflam_dolo_25_mg', 'cetirizin_10_mg', 'cold_fx', 'coldrex', 'concor_10_mg', 'concor_5_mg', 'condrosulf_800_mg', 'controloc_20_mg', 'covercard_plus_10_mg_2_5_mg_5_mg', 'coverex_4_mg', 'diclopram_75-mg_20-mg', 'dorithricin_mentol', 'dulsevia_60_mg', 'enterol_250_mg', 'favipiravir_meditop_200_mg', 'ibumax_400_mg', 'jutavit_c_vitamin', 'jutavit_cink', 'kalcium_magnezium_cink', 'kalium_r', 'koleszterin_kontroll', 'lactamed', 'lactiv_plus', 'laresin_10_mg', 'letrox_50_mikrogramm', 'lordestin_5_mg', 'merckformin_xr_1000_mg', 'meridian', 'metothyrin_10_mg', 'mezym_forte_10_000_egyseg', 'milgamma', 'milurit_300_mg', 'naprosyn_250_mg', 'narva_sr_1_5_mg_retard', 'naturland_d_vitamin_forte', 'nebivolol_sandoz_5_mg', 'neo_citran', 'neo_ferro_folgamma_114_mg_0_8_mg', 'nolpaza_20_mg', 'normodipine_5_mg', 'novo_c_plus', 'nurofen_forte_400_mg', 'ocutein', 'olicard_60_mg', 'quamatel_40_mg', 'rubophen_500_mg', 'salazopyrin_en_500_mg', 'sedatif_pc', 'semicillin_500_mg', 'sicor_10_mg', 'sinupret_forte', 'strepfen_8_75_mg', 'strepsils', 'teva_ambrobene_30_mg', 'teva_enterobene_2_mg', 'theospirex_150_mg', 'tricovel_tricoage45', 'tritace_5_mg', 'tritace_hct_5_mg_25_mg', 'urotrin', 'urzinol', 'valeriana_teva', 'verospiron_25_mg', 'vita_c', 'vitamin_d3_fresenius_1000_ne', 'voltaren_dolo_rapid_25_mg', 'xeter_20_mg', 'zadex_60_mg']\n",
      "Training images: 59\n",
      "Validation images: 15\n",
      "Test images: 16\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of classes: {len(dataset.classes)}\")\n",
    "print(f\"Class names: {dataset.classes}\")\n",
    "print(f\"Training images: {len(train_dataset)}\")\n",
    "print(f\"Validation images: {len(val_dataset)}\")\n",
    "print(f\"Test images: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50adc37",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "We use a pretrained MobileNetV3-Large as the backbone for pill classification.\n",
    "\n",
    "The convolutional feature extractor is frozen to retain learned visual patterns from ImageNet,\n",
    "and the final classifier layer is replaced to match our 84 pill classes.\n",
    "\n",
    "We will train the model on a small dataset, so we will only train the last layer of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f52b4b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "MedsClassifier                                          [1, 84]                   --\n",
       "â”œâ”€MobileNetV3: 1-1                                      [1, 84]                   --\n",
       "â”‚    â””â”€Sequential: 2-1                                  [1, 960, 7, 7]            --\n",
       "â”‚    â”‚    â””â”€Conv2dNormActivation: 3-1                   [1, 16, 112, 112]         (464)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-2                       [1, 16, 112, 112]         (464)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-3                       [1, 24, 56, 56]           (3,440)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-4                       [1, 24, 56, 56]           (4,440)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-5                       [1, 40, 28, 28]           (10,328)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-6                       [1, 40, 28, 28]           (20,992)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-7                       [1, 40, 28, 28]           (20,992)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-8                       [1, 80, 14, 14]           (32,080)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-9                       [1, 80, 14, 14]           (34,760)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-10                      [1, 80, 14, 14]           (31,992)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-11                      [1, 80, 14, 14]           (31,992)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-12                      [1, 112, 14, 14]          (214,424)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-13                      [1, 112, 14, 14]          (386,120)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-14                      [1, 160, 7, 7]            (429,224)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-15                      [1, 160, 7, 7]            (797,360)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-16                      [1, 160, 7, 7]            (797,360)\n",
       "â”‚    â”‚    â””â”€Conv2dNormActivation: 3-17                  [1, 960, 7, 7]            (155,520)\n",
       "â”‚    â””â”€AdaptiveAvgPool2d: 2-2                           [1, 960, 1, 1]            --\n",
       "â”‚    â””â”€Sequential: 2-3                                  [1, 84]                   --\n",
       "â”‚    â”‚    â””â”€Linear: 3-18                                [1, 1280]                 1,230,080\n",
       "â”‚    â”‚    â””â”€Hardswish: 3-19                             [1, 1280]                 --\n",
       "â”‚    â”‚    â””â”€Dropout: 3-20                               [1, 1280]                 --\n",
       "â”‚    â”‚    â””â”€Linear: 3-21                                [1, 84]                   107,604\n",
       "=========================================================================================================\n",
       "Total params: 4,309,636\n",
       "Trainable params: 1,337,684\n",
       "Non-trainable params: 2,971,952\n",
       "Total mult-adds (M): 215.45\n",
       "=========================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 70.45\n",
       "Params size (MB): 17.24\n",
       "Estimated Total Size (MB): 88.29\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import MedsClassifier\n",
    "from torchinfo import summary\n",
    "\n",
    "model = MedsClassifier(len(dataset.classes)).to(device)\n",
    "\n",
    "summary(model, input_size=(1, 3, 224, 224), device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da985cd",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95cff6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 64\u001b[0m\n\u001b[1;32m     62\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# The age of training\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Switching the model to validation mode\u001b[39;00m\n\u001b[1;32m     67\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch_index)\u001b[0m\n\u001b[1;32m     15\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[1;32m     16\u001b[0m last_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_index, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtrain_loader\u001b[49m):\n\u001b[1;32m     19\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     20\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "EPOCHS = 20\n",
    "best_vloss = 1e5\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "def train_one_epoch(epoch_index):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    for batch_index, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if batch_index % 10 == 9:\n",
    "            last_loss = running_loss / 10. # average loss by 10 batches\n",
    "            print(f'Epoch: {epoch_index + 1}, batch: {batch_index}, loss: {last_loss}')\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss\n",
    "\n",
    "def evaluate_loss_acc(dataloader):\n",
    "    \"\"\"Return (avg_loss, accuracy) computed with torch only.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            total_correct += (preds == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    acc = total_correct / max(1, total_samples)\n",
    "    return avg_loss, acc, y_true, y_pred\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "\n",
    "    # Switching the model to training mode\n",
    "    model.train(True)\n",
    "    # The age of training\n",
    "    avg_loss = train_one_epoch(epoch)\n",
    "\n",
    "    # Switching the model to validation mode\n",
    "    model.eval()\n",
    "    running_vloss = 0.0\n",
    "\n",
    "    # Validation\n",
    "    train_loss, train_acc, y_true_train, y_pred_train = evaluate_loss_acc(train_loader)\n",
    "    val_loss,  val_acc, y_true_val, y_pred_val  = evaluate_loss_acc(val_loader)\n",
    "\n",
    "    print(f\"Training  - loss: {train_loss:.4f}, accuracy: {train_acc*100:.2f}%\")\n",
    "    print(f\"Validation - loss: {val_loss:.4f},  accuracy: {val_acc*100:.2f}%\")\n",
    "\n",
    "    # Saving the best model\n",
    "    if val_loss < best_test_loss:\n",
    "        best_test_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"models/meds_classifier.pt\")\n",
    "\n",
    "    if val_acc >= 0.75:\n",
    "        print(f\"ðŸŽ¯ Target validation accuracy reached ({val_acc*100:.2f}%). Stopping.\")\n",
    "        break\n",
    "    \n",
    "    print(\"Best model saved as models/meds_classifier.pt\")\n",
    "\n",
    "print(\"\\nðŸ“Š Final evaluation on test set:\")\n",
    "test_loss, test_acc, y_true_test, y_pred_test = evaluate_loss_acc(test_loader)\n",
    "print(f\"Test - loss: {test_loss:.4f}, accuracy: {test_acc*100:.2f}%\")\n",
    "\n",
    "print(classification_report(\n",
    "    y_true_test,\n",
    "    y_pred_test,\n",
    "    target_names=test_dataset_origin.classes,\n",
    "    digits=3,\n",
    "    zero_division=0\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
