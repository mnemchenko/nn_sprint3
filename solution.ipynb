{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa7ff55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available:  False\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Is CUDA available: \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207a4125",
   "metadata": {},
   "source": [
    "### Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d584d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "\n",
    "train_dataset_path = 'dataset/ogyeiv2/train'\n",
    "dataset = ImageFolder(train_dataset_path)\n",
    "train_dataset, val_dataset = random_split(dataset, [0.8, 0.2]) \n",
    "\n",
    "test_dataset_path = 'dataset/ogyeiv2/test'\n",
    "test_dataset_origin = ImageFolder(test_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cd8a55",
   "metadata": {},
   "source": [
    "We're going to use a model pretrained on ImageNet, so it's best to normalize our dataset accordingly to match the model's training data.\n",
    "\n",
    "The transforms.ColorJitter function simulates lighting and exposure changes by randomly varying image brightness and contrast by Â±25%. This helps the model stay robust to illumination differences and focus on shape and texture instead of light intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1951ccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_pipeline import MedsDataPipeline\n",
    "\n",
    "data = MedsDataPipeline(train_dataset, val_dataset, test_dataset_origin, batch_size=32)\n",
    "data.setup()\n",
    "\n",
    "train_loader = data.train_dataloader()\n",
    "val_loader = data.val_dataloader()\n",
    "test_loader = data.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28d87b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 84\n",
      "Class names: ['acc_long_600_mg', 'advil_ultra_forte', 'akineton_2_mg', 'algoflex_forte_dolo_400_mg', 'algoflex_rapid_400_mg', 'algopyrin_500_mg', 'ambroxol_egis_30_mg', 'apranax_550_mg', 'aspirin_ultra_500_mg', 'atoris_20_mg', 'atorvastatin_teva_20_mg', 'betaloc_50_mg', 'bila_git', 'c_vitamin_teva_500_mg', 'calci_kid', 'cataflam_50_mg', 'cataflam_dolo_25_mg', 'cetirizin_10_mg', 'cold_fx', 'coldrex', 'concor_10_mg', 'concor_5_mg', 'condrosulf_800_mg', 'controloc_20_mg', 'covercard_plus_10_mg_2_5_mg_5_mg', 'coverex_4_mg', 'diclopram_75-mg_20-mg', 'dorithricin_mentol', 'dulsevia_60_mg', 'enterol_250_mg', 'favipiravir_meditop_200_mg', 'ibumax_400_mg', 'jutavit_c_vitamin', 'jutavit_cink', 'kalcium_magnezium_cink', 'kalium_r', 'koleszterin_kontroll', 'lactamed', 'lactiv_plus', 'laresin_10_mg', 'letrox_50_mikrogramm', 'lordestin_5_mg', 'merckformin_xr_1000_mg', 'meridian', 'metothyrin_10_mg', 'mezym_forte_10_000_egyseg', 'milgamma', 'milurit_300_mg', 'naprosyn_250_mg', 'narva_sr_1_5_mg_retard', 'naturland_d_vitamin_forte', 'nebivolol_sandoz_5_mg', 'neo_citran', 'neo_ferro_folgamma_114_mg_0_8_mg', 'nolpaza_20_mg', 'normodipine_5_mg', 'novo_c_plus', 'nurofen_forte_400_mg', 'ocutein', 'olicard_60_mg', 'quamatel_40_mg', 'rubophen_500_mg', 'salazopyrin_en_500_mg', 'sedatif_pc', 'semicillin_500_mg', 'sicor_10_mg', 'sinupret_forte', 'strepfen_8_75_mg', 'strepsils', 'teva_ambrobene_30_mg', 'teva_enterobene_2_mg', 'theospirex_150_mg', 'tricovel_tricoage45', 'tritace_5_mg', 'tritace_hct_5_mg_25_mg', 'urotrin', 'urzinol', 'valeriana_teva', 'verospiron_25_mg', 'vita_c', 'vitamin_d3_fresenius_1000_ne', 'voltaren_dolo_rapid_25_mg', 'xeter_20_mg', 'zadex_60_mg']\n",
      "Training images: 1882\n",
      "Validation images: 470\n",
      "Test images: 504\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of classes: {len(dataset.classes)}\")\n",
    "print(f\"Class names: {dataset.classes}\")\n",
    "print(f\"Training images: {len(data.train_dataset)}\")\n",
    "print(f\"Validation images: {len(data.val_dataset)}\")\n",
    "print(f\"Test images: {len(data.test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50adc37",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "We use a pretrained MobileNetV3-Large as the backbone for pill classification.\n",
    "\n",
    "The convolutional feature extractor is frozen to retain learned visual patterns from ImageNet,\n",
    "and the final classifier layer is replaced to match our 84 pill classes.\n",
    "\n",
    "We will train the model on a small dataset, so we will only train the last layer of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f52b4b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "MedsClassifier                                          [1, 84]                   --\n",
       "â”œâ”€MobileNetV3: 1-1                                      [1, 84]                   --\n",
       "â”‚    â””â”€Sequential: 2-1                                  [1, 960, 7, 7]            --\n",
       "â”‚    â”‚    â””â”€Conv2dNormActivation: 3-1                   [1, 16, 112, 112]         (464)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-2                       [1, 16, 112, 112]         (464)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-3                       [1, 24, 56, 56]           (3,440)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-4                       [1, 24, 56, 56]           (4,440)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-5                       [1, 40, 28, 28]           (10,328)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-6                       [1, 40, 28, 28]           (20,992)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-7                       [1, 40, 28, 28]           (20,992)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-8                       [1, 80, 14, 14]           (32,080)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-9                       [1, 80, 14, 14]           (34,760)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-10                      [1, 80, 14, 14]           (31,992)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-11                      [1, 80, 14, 14]           (31,992)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-12                      [1, 112, 14, 14]          (214,424)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-13                      [1, 112, 14, 14]          (386,120)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-14                      [1, 160, 7, 7]            (429,224)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-15                      [1, 160, 7, 7]            (797,360)\n",
       "â”‚    â”‚    â””â”€InvertedResidual: 3-16                      [1, 160, 7, 7]            (797,360)\n",
       "â”‚    â”‚    â””â”€Conv2dNormActivation: 3-17                  [1, 960, 7, 7]            (155,520)\n",
       "â”‚    â””â”€AdaptiveAvgPool2d: 2-2                           [1, 960, 1, 1]            --\n",
       "â”‚    â””â”€Sequential: 2-3                                  [1, 84]                   --\n",
       "â”‚    â”‚    â””â”€Linear: 3-18                                [1, 1280]                 1,230,080\n",
       "â”‚    â”‚    â””â”€Hardswish: 3-19                             [1, 1280]                 --\n",
       "â”‚    â”‚    â””â”€Dropout: 3-20                               [1, 1280]                 --\n",
       "â”‚    â”‚    â””â”€Linear: 3-21                                [1, 84]                   107,604\n",
       "=========================================================================================================\n",
       "Total params: 4,309,636\n",
       "Trainable params: 1,337,684\n",
       "Non-trainable params: 2,971,952\n",
       "Total mult-adds (M): 215.45\n",
       "=========================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 70.45\n",
       "Params size (MB): 17.24\n",
       "Estimated Total Size (MB): 88.29\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import MedsClassifier\n",
    "from torchinfo import summary\n",
    "\n",
    "model = MedsClassifier(len(dataset.classes)).to(device)\n",
    "\n",
    "summary(model, input_size=(1, 3, 224, 224), device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da985cd",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95cff6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch: 1, batch: 9, loss: 4.4261\n",
      "Epoch: 1, batch: 19, loss: 4.3110\n",
      "Epoch: 1, batch: 29, loss: 4.0800\n",
      "Epoch: 1, batch: 39, loss: 3.9568\n",
      "Epoch: 1, batch: 49, loss: 3.6716\n",
      "Training  - loss: 3.7175, accuracy: 14.56%\n",
      "Validation - loss: 3.7163,  accuracy: 15.32%\n",
      "âœ… Model improved and saved\n",
      "Epoch 2/20\n",
      "Epoch: 2, batch: 9, loss: 3.1296\n",
      "Epoch: 2, batch: 19, loss: 2.8309\n",
      "Epoch: 2, batch: 29, loss: 2.7139\n",
      "Epoch: 2, batch: 39, loss: 2.6633\n",
      "Epoch: 2, batch: 49, loss: 2.4300\n",
      "Training  - loss: 3.0294, accuracy: 21.15%\n",
      "Validation - loss: 3.1536,  accuracy: 18.51%\n",
      "âœ… Model improved and saved\n",
      "Epoch 3/20\n",
      "Epoch: 3, batch: 9, loss: 2.1240\n",
      "Epoch: 3, batch: 19, loss: 1.9945\n",
      "Epoch: 3, batch: 29, loss: 2.0669\n",
      "Epoch: 3, batch: 39, loss: 1.9184\n",
      "Epoch: 3, batch: 49, loss: 1.8917\n",
      "Training  - loss: 2.5444, accuracy: 29.91%\n",
      "Validation - loss: 2.6191,  accuracy: 29.36%\n",
      "âœ… Model improved and saved\n",
      "Epoch 4/20\n",
      "Epoch: 4, batch: 9, loss: 1.6930\n",
      "Epoch: 4, batch: 19, loss: 1.8178\n",
      "Epoch: 4, batch: 29, loss: 1.5505\n",
      "Epoch: 4, batch: 39, loss: 1.4339\n",
      "Epoch: 4, batch: 49, loss: 1.7360\n",
      "Training  - loss: 1.7402, accuracy: 51.65%\n",
      "Validation - loss: 1.7700,  accuracy: 53.19%\n",
      "âœ… Model improved and saved\n",
      "Epoch 5/20\n",
      "Epoch: 5, batch: 9, loss: 1.4615\n",
      "Epoch: 5, batch: 19, loss: 1.4589\n",
      "Epoch: 5, batch: 29, loss: 1.4782\n",
      "Epoch: 5, batch: 39, loss: 1.5054\n",
      "Epoch: 5, batch: 49, loss: 1.3675\n",
      "Training  - loss: 1.3471, accuracy: 60.20%\n",
      "Validation - loss: 1.3179,  accuracy: 61.28%\n",
      "âœ… Model improved and saved\n",
      "Epoch 6/20\n",
      "Epoch: 6, batch: 9, loss: 1.3229\n",
      "Epoch: 6, batch: 19, loss: 1.3841\n",
      "Epoch: 6, batch: 29, loss: 1.3403\n",
      "Epoch: 6, batch: 39, loss: 1.2959\n",
      "Epoch: 6, batch: 49, loss: 1.2077\n",
      "Training  - loss: 1.1835, accuracy: 65.94%\n",
      "Validation - loss: 1.2324,  accuracy: 63.40%\n",
      "âœ… Model improved and saved\n",
      "Epoch 7/20\n",
      "Epoch: 7, batch: 9, loss: 1.3182\n",
      "Epoch: 7, batch: 19, loss: 1.2552\n",
      "Epoch: 7, batch: 29, loss: 1.1756\n",
      "Epoch: 7, batch: 39, loss: 1.1797\n",
      "Epoch: 7, batch: 49, loss: 1.1826\n",
      "Training  - loss: 0.9325, accuracy: 72.37%\n",
      "Validation - loss: 0.9983,  accuracy: 68.94%\n",
      "âœ… Model improved and saved\n",
      "Epoch 8/20\n",
      "Epoch: 8, batch: 9, loss: 1.1038\n",
      "Epoch: 8, batch: 19, loss: 1.1091\n",
      "Epoch: 8, batch: 29, loss: 1.1170\n",
      "Epoch: 8, batch: 39, loss: 1.0712\n",
      "Epoch: 8, batch: 49, loss: 1.1914\n",
      "Training  - loss: 0.8850, accuracy: 72.85%\n",
      "Validation - loss: 0.9660,  accuracy: 71.49%\n",
      "âœ… Model improved and saved\n",
      "Epoch 9/20\n",
      "Epoch: 9, batch: 9, loss: 0.9997\n",
      "Epoch: 9, batch: 19, loss: 1.1304\n",
      "Epoch: 9, batch: 29, loss: 1.0364\n",
      "Epoch: 9, batch: 39, loss: 1.1253\n",
      "Epoch: 9, batch: 49, loss: 1.0581\n",
      "Training  - loss: 0.8555, accuracy: 74.07%\n",
      "Validation - loss: 0.8841,  accuracy: 70.64%\n",
      "âœ… Model improved and saved\n",
      "Epoch 10/20\n",
      "Epoch: 10, batch: 9, loss: 1.0344\n",
      "Epoch: 10, batch: 19, loss: 0.9356\n",
      "Epoch: 10, batch: 29, loss: 1.0773\n",
      "Epoch: 10, batch: 39, loss: 0.9892\n",
      "Epoch: 10, batch: 49, loss: 1.0993\n",
      "Training  - loss: 0.8040, accuracy: 75.45%\n",
      "Validation - loss: 0.8729,  accuracy: 73.40%\n",
      "âœ… Model improved and saved\n",
      "Epoch 11/20\n",
      "Epoch: 11, batch: 9, loss: 0.9695\n",
      "Epoch: 11, batch: 19, loss: 1.0170\n",
      "Epoch: 11, batch: 29, loss: 0.9867\n",
      "Epoch: 11, batch: 39, loss: 0.8448\n",
      "Epoch: 11, batch: 49, loss: 0.9941\n",
      "Training  - loss: 0.8377, accuracy: 74.34%\n",
      "Validation - loss: 0.8694,  accuracy: 72.34%\n",
      "âœ… Model improved and saved\n",
      "Epoch 12/20\n",
      "Epoch: 12, batch: 9, loss: 1.0294\n",
      "Epoch: 12, batch: 19, loss: 0.8319\n",
      "Epoch: 12, batch: 29, loss: 0.8876\n",
      "Epoch: 12, batch: 39, loss: 0.9918\n",
      "Epoch: 12, batch: 49, loss: 1.0874\n",
      "Training  - loss: 0.7636, accuracy: 77.42%\n",
      "Validation - loss: 0.8425,  accuracy: 73.40%\n",
      "âœ… Model improved and saved\n",
      "Epoch 13/20\n",
      "Epoch: 13, batch: 9, loss: 0.8620\n",
      "Epoch: 13, batch: 19, loss: 0.8224\n",
      "Epoch: 13, batch: 29, loss: 0.9581\n",
      "Epoch: 13, batch: 39, loss: 0.9634\n",
      "Epoch: 13, batch: 49, loss: 0.9994\n",
      "Training  - loss: 0.6862, accuracy: 78.69%\n",
      "Validation - loss: 0.6979,  accuracy: 78.72%\n",
      "âœ… Model improved and saved\n",
      "ðŸŽ¯ Target validation accuracy reached (78.72%). Stopping.\n",
      "\n",
      "ðŸ“Š Final evaluation on test set:\n",
      "Test - loss: 0.6781, accuracy: 77.78%\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "                 acc_long_600_mg      1.000     1.000     1.000         6\n",
      "               advil_ultra_forte      1.000     1.000     1.000         6\n",
      "                   akineton_2_mg      1.000     0.667     0.800         6\n",
      "      algoflex_forte_dolo_400_mg      1.000     1.000     1.000         6\n",
      "           algoflex_rapid_400_mg      1.000     1.000     1.000         6\n",
      "                algopyrin_500_mg      0.750     1.000     0.857         6\n",
      "             ambroxol_egis_30_mg      0.714     0.833     0.769         6\n",
      "                  apranax_550_mg      0.667     1.000     0.800         6\n",
      "            aspirin_ultra_500_mg      0.545     1.000     0.706         6\n",
      "                    atoris_20_mg      0.750     0.500     0.600         6\n",
      "         atorvastatin_teva_20_mg      0.556     0.833     0.667         6\n",
      "                   betaloc_50_mg      0.667     1.000     0.800         6\n",
      "                        bila_git      1.000     1.000     1.000         6\n",
      "           c_vitamin_teva_500_mg      0.857     1.000     0.923         6\n",
      "                       calci_kid      0.857     1.000     0.923         6\n",
      "                  cataflam_50_mg      1.000     1.000     1.000         6\n",
      "             cataflam_dolo_25_mg      1.000     1.000     1.000         6\n",
      "                 cetirizin_10_mg      0.833     0.833     0.833         6\n",
      "                         cold_fx      1.000     0.833     0.909         6\n",
      "                         coldrex      1.000     1.000     1.000         6\n",
      "                    concor_10_mg      1.000     0.500     0.667         6\n",
      "                     concor_5_mg      1.000     0.500     0.667         6\n",
      "               condrosulf_800_mg      0.857     1.000     0.923         6\n",
      "                 controloc_20_mg      0.800     0.667     0.727         6\n",
      "covercard_plus_10_mg_2_5_mg_5_mg      0.667     0.333     0.444         6\n",
      "                    coverex_4_mg      0.667     1.000     0.800         6\n",
      "           diclopram_75-mg_20-mg      1.000     1.000     1.000         6\n",
      "              dorithricin_mentol      0.857     1.000     0.923         6\n",
      "                  dulsevia_60_mg      0.857     1.000     0.923         6\n",
      "                  enterol_250_mg      1.000     0.500     0.667         6\n",
      "      favipiravir_meditop_200_mg      0.600     1.000     0.750         6\n",
      "                   ibumax_400_mg      0.667     1.000     0.800         6\n",
      "               jutavit_c_vitamin      0.833     0.833     0.833         6\n",
      "                    jutavit_cink      0.600     0.500     0.545         6\n",
      "          kalcium_magnezium_cink      0.500     0.333     0.400         6\n",
      "                        kalium_r      0.800     0.667     0.727         6\n",
      "            koleszterin_kontroll      0.714     0.833     0.769         6\n",
      "                        lactamed      0.750     1.000     0.857         6\n",
      "                     lactiv_plus      0.000     0.000     0.000         6\n",
      "                   laresin_10_mg      1.000     0.667     0.800         6\n",
      "            letrox_50_mikrogramm      0.600     1.000     0.750         6\n",
      "                  lordestin_5_mg      0.750     1.000     0.857         6\n",
      "          merckformin_xr_1000_mg      0.500     1.000     0.667         6\n",
      "                        meridian      0.333     0.500     0.400         6\n",
      "                metothyrin_10_mg      0.857     1.000     0.923         6\n",
      "       mezym_forte_10_000_egyseg      0.857     1.000     0.923         6\n",
      "                        milgamma      0.500     0.833     0.625         6\n",
      "                  milurit_300_mg      1.000     0.333     0.500         6\n",
      "                 naprosyn_250_mg      0.857     1.000     0.923         6\n",
      "          narva_sr_1_5_mg_retard      0.750     0.500     0.600         6\n",
      "       naturland_d_vitamin_forte      0.333     0.167     0.222         6\n",
      "           nebivolol_sandoz_5_mg      0.333     0.333     0.333         6\n",
      "                      neo_citran      1.000     0.167     0.286         6\n",
      "neo_ferro_folgamma_114_mg_0_8_mg      1.000     1.000     1.000         6\n",
      "                   nolpaza_20_mg      0.500     0.333     0.400         6\n",
      "                normodipine_5_mg      0.500     0.667     0.571         6\n",
      "                     novo_c_plus      0.833     0.833     0.833         6\n",
      "            nurofen_forte_400_mg      0.750     0.500     0.600         6\n",
      "                         ocutein      1.000     1.000     1.000         6\n",
      "                   olicard_60_mg      0.714     0.833     0.769         6\n",
      "                  quamatel_40_mg      1.000     0.833     0.909         6\n",
      "                 rubophen_500_mg      0.667     0.333     0.444         6\n",
      "           salazopyrin_en_500_mg      0.857     1.000     0.923         6\n",
      "                      sedatif_pc      0.000     0.000     0.000         6\n",
      "               semicillin_500_mg      1.000     0.833     0.909         6\n",
      "                     sicor_10_mg      0.600     1.000     0.750         6\n",
      "                  sinupret_forte      1.000     1.000     1.000         6\n",
      "                strepfen_8_75_mg      1.000     0.833     0.909         6\n",
      "                       strepsils      1.000     1.000     1.000         6\n",
      "            teva_ambrobene_30_mg      0.500     0.500     0.500         6\n",
      "            teva_enterobene_2_mg      0.500     0.167     0.250         6\n",
      "               theospirex_150_mg      0.500     0.500     0.500         6\n",
      "             tricovel_tricoage45      1.000     1.000     1.000         6\n",
      "                    tritace_5_mg      1.000     0.667     0.800         6\n",
      "          tritace_hct_5_mg_25_mg      0.571     0.667     0.615         6\n",
      "                         urotrin      1.000     1.000     1.000         6\n",
      "                         urzinol      1.000     1.000     1.000         6\n",
      "                  valeriana_teva      1.000     1.000     1.000         6\n",
      "                verospiron_25_mg      0.857     1.000     0.923         6\n",
      "                          vita_c      1.000     1.000     1.000         6\n",
      "    vitamin_d3_fresenius_1000_ne      0.800     0.667     0.727         6\n",
      "       voltaren_dolo_rapid_25_mg      1.000     0.833     0.909         6\n",
      "                     xeter_20_mg      1.000     0.667     0.800         6\n",
      "                     zadex_60_mg      0.857     1.000     0.923         6\n",
      "\n",
      "                        accuracy                          0.778       504\n",
      "                       macro avg      0.786     0.778     0.759       504\n",
      "                    weighted avg      0.786     0.778     0.759       504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report\n",
    "from train_utils import train_one_epoch, evaluate_loss_acc\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "EPOCHS = 20\n",
    "best_vloss = 1e5\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "\n",
    "    # The age of training\n",
    "    train_one_epoch(model, train_loader, optimizer, criterion, device, epoch)\n",
    "\n",
    "    # Validation\n",
    "    train_loss, train_acc, y_true_train, y_pred_train = evaluate_loss_acc(model, train_loader, criterion, device)\n",
    "    val_loss,  val_acc, y_true_val, y_pred_val  = evaluate_loss_acc(model, val_loader, criterion, device)\n",
    "\n",
    "    print(f\"Training  - loss: {train_loss:.4f}, accuracy: {train_acc*100:.2f}%\")\n",
    "    print(f\"Validation - loss: {val_loss:.4f},  accuracy: {val_acc*100:.2f}%\")\n",
    "\n",
    "    # Saving the best model\n",
    "    if val_loss < best_test_loss:\n",
    "        best_test_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"models/meds_classifier.pt\")\n",
    "        print(\"âœ… Model improved and saved\")\n",
    "\n",
    "    if val_acc >= 0.75:\n",
    "        print(f\"ðŸŽ¯ Target validation accuracy reached ({val_acc*100:.2f}%). Stopping.\")\n",
    "        break\n",
    "\n",
    "print(\"\\nðŸ“Š Final evaluation on test set:\")\n",
    "model.load_state_dict(torch.load(\"models/meds_classifier.pt\"))\n",
    "test_loss, test_acc, y_true_test, y_pred_test = evaluate_loss_acc(model, test_loader, criterion, device)\n",
    "print(f\"Test - loss: {test_loss:.4f}, accuracy: {test_acc*100:.2f}%\")\n",
    "\n",
    "print(classification_report(\n",
    "    y_true_test,\n",
    "    y_pred_test,\n",
    "    target_names=test_dataset_origin.classes,\n",
    "    digits=3,\n",
    "    zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abec6b9e",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "#### In which 5 classes does the model make mistakes most often?\n",
    "sedatif_pc - completely unrecognized\n",
    "\n",
    "lactiv_plus - completely unrecognized\n",
    "\n",
    "naturland_d_vitamin_forte - almost all predictions are wrong\n",
    "\n",
    "covercard_plus_10_mg_2_5_mg_5_mg - serious errors\n",
    "\n",
    "teva_enterobene_2_mg - serious errors\n",
    "\n",
    "#### Why the model may make mistakes on these classes\n",
    "\n",
    "Lack of distinctive and informative features â€” the tablets are white, smooth, without engravings, textures, or color variations, so the model cannot find stable features to differentiate between them.\n",
    "\n",
    "Image capture issues â€” overexposure, poor contrast, uneven lighting, and loss of fine details or textures prevent the CNN from perceiving the actual shape relief or imprinted text.\n",
    "\n",
    "#### In which classes does the model not make mistakes?\n",
    "acc_long_600_mg\n",
    "\n",
    "advil_ultra_forte\n",
    "\n",
    "algoflex_forte_dolo_400_mg\n",
    "\n",
    "cataflam_dolo_25_mg\n",
    "\n",
    "ocutein\n",
    "\n",
    "strepsils\n",
    "\n",
    "urzinol\n",
    "\n",
    "valeriana_teva\n",
    "\n",
    "#### Why the model recognizes these classes without errors\n",
    "\n",
    "The tablets in these classes have clear and distinctive visual features â€” such as color, pattern, shape, or engravings â€” that remain visible even under imperfect lighting or slight overexposure.\n",
    "\n",
    "These unique characteristics provide stable visual cues for the neural network, making it easier to differentiate them from other tablets regardless of variations in lighting, angle, or background.\n",
    "\n",
    "#### How can the classifierâ€™s accuracy be improved?\n",
    "\n",
    "1. _Photograph both sides of the tablet._ Some tablets have engravings or text only on one side, so capturing both sides provides the model with more distinguishing information.\n",
    "2. _Increase the contrast during image capture._ Avoid overexposure and ensure that engravings and textures are clearly visible â€” this helps the model recognize surface details more effectively.\n",
    "3. _Use angled lighting to emphasize shape and relief._ Side lighting creates subtle shadows that highlight the tabletâ€™s contours and engraved details.\n",
    "4. _Use a neutral gray background._ A slightly darker gray background improves contrast with white tablets and avoids introducing misleading color cues for the model.\n",
    "5. _Photograph tablets at a slight angle to capture 3D features._ Angled shots reveal thickness and shape, helping the model distinguish visually similar tablets.\n",
    "6. _Use a size reference grid._ A grid helps the model learn scale and relative size, but it should be neutral, low-contrast, and consistent, so it doesnâ€™t become a dominant visual feature.\n",
    "\n",
    "#### How else can the modelâ€™s results and errors be analyzed?\n",
    "\n",
    "Build a confusion matrix â€” it immediately shows which classes are being confused with each other.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
